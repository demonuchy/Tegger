import { useState, useCallback, useRef, useEffect } from 'react';
import * as cocoSsd from '@tensorflow-models/coco-ssd';
import '@tensorflow/tfjs';

export const useDocumentScanner = () => {
  const [isCameraActive, setIsCameraActive] = useState(false);
  const cameraRef = useRef(null);
  const [model, setModel] = useState(null);
  const detectionIntervalRef = useRef(null);
  const [onDocumentDetected, setOnDocumentDetected] = useState(null);

  useEffect(() => {
    const loadModel = async () => {
      try {
        console.log('ðŸ”„ Ð—Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° Ð¼Ð¾Ð´ÐµÐ»Ð¸ ÐºÐ¾Ð¼Ð¿ÑŒÑŽÑ‚ÐµÑ€Ð½Ð¾Ð³Ð¾ Ð·Ñ€ÐµÐ½Ð¸Ñ...');
        const loadedModel = await cocoSsd.load();
        setModel(loadedModel);
        console.log('âœ… ÐœÐ¾Ð´ÐµÐ»ÑŒ Ð·Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½Ð° ÑƒÑÐ¿ÐµÑˆÐ½Ð¾');
      } catch (error) {
        console.error('âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð·Ð°Ð³Ñ€ÑƒÐ·ÐºÐ¸ Ð¼Ð¾Ð´ÐµÐ»Ð¸:', error);
      }
    };
    loadModel();
  }, []);

  const startCamera = useCallback((onDetectedCallback = null) => {
    console.log('ðŸ“· Ð—Ð°Ð¿ÑƒÑÐº ÐºÐ°Ð¼ÐµÑ€Ñ‹');
    setIsCameraActive(true);
    if (onDetectedCallback) {
      setOnDocumentDetected(() => onDetectedCallback);
    }
  }, []);

  const stopCamera = useCallback(() => {
    console.log('ðŸ›‘ ÐžÑÑ‚Ð°Ð½Ð¾Ð²ÐºÐ° ÐºÐ°Ð¼ÐµÑ€Ñ‹');
    setIsCameraActive(false);
    setOnDocumentDetected(null);
    if (detectionIntervalRef.current) {
      clearInterval(detectionIntervalRef.current);
      detectionIntervalRef.current = null;
    }
  }, []);

  // ÐÐžÐ’ÐÐ¯ Ð¤Ð£ÐÐšÐ¦Ð˜Ð¯: Ð—Ð°Ñ…Ð²Ð°Ñ‚ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð¾Ð±Ð»Ð°ÑÑ‚Ð¸ Ñ€Ð°Ð¼ÐºÐ¸
  const captureFrameArea = useCallback(() => {
    if (cameraRef.current && cameraRef.current.video) {
      try {
        const video = cameraRef.current.video;
        const canvas = document.createElement('canvas');
        const ctx = canvas.getContext('2d');
        
        // Ð Ð°Ð·Ð¼ÐµÑ€Ñ‹ Ð¾Ð±Ð»Ð°ÑÑ‚Ð¸ Ñ€Ð°Ð¼ÐºÐ¸ (ÑÐ¾Ð²Ð¿Ð°Ð´Ð°ÑŽÑ‚ Ñ CSS)
        const frameWidth = 350;
        const frameHeight = 250;
        
        // ÐŸÐ¾Ð·Ð¸Ñ†Ð¸Ñ Ñ€Ð°Ð¼ÐºÐ¸ (Ñ†ÐµÐ½Ñ‚Ñ€ ÑÐºÑ€Ð°Ð½Ð°)
        const frameX = (video.videoWidth - frameWidth) / 2;
        const frameY = (video.videoHeight - frameHeight) / 2;
        
        // ÐÐ°ÑÑ‚Ñ€Ð°Ð¸Ð²Ð°ÐµÐ¼ canvas Ð¿Ð¾Ð´ Ñ€Ð°Ð·Ð¼ÐµÑ€ Ñ€Ð°Ð¼ÐºÐ¸
        canvas.width = frameWidth;
        canvas.height = frameHeight;
        
        // Ð Ð¸ÑÑƒÐµÐ¼ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð¾Ð±Ð»Ð°ÑÑ‚ÑŒ Ñ€Ð°Ð¼ÐºÐ¸
        ctx.drawImage(
          video, 
          frameX, frameY, frameWidth, frameHeight, // source: Ð¾Ð±Ð»Ð°ÑÑ‚ÑŒ Ð¸Ð· Ð²Ð¸Ð´ÐµÐ¾
          0, 0, frameWidth, frameHeight            // destination: Ð²ÐµÑÑŒ canvas
        );
        
        // ÐšÐ¾Ð½Ð²ÐµÑ€Ñ‚Ð¸Ñ€ÑƒÐµÐ¼ Ð² base64
        const imageSrc = canvas.toDataURL('image/jpeg', 0.9);
        console.log('âœ… ÐžÐ±Ð»Ð°ÑÑ‚ÑŒ Ñ€Ð°Ð¼ÐºÐ¸ Ð·Ð°Ñ…Ð²Ð°Ñ‡ÐµÐ½Ð° ÑƒÑÐ¿ÐµÑˆÐ½Ð¾');
        return imageSrc;
      } catch (error) {
        console.error('âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¿Ñ€Ð¸ Ð·Ð°Ñ…Ð²Ð°Ñ‚Ðµ Ð¾Ð±Ð»Ð°ÑÑ‚Ð¸ Ñ€Ð°Ð¼ÐºÐ¸:', error);
        return null;
      }
    }
    console.warn('âš ï¸ Camera ref Ð½Ðµ Ð´Ð¾ÑÑ‚ÑƒÐ¿ÐµÐ½');
    return null;
  }, []);

  // Ð¤ÑƒÐ½ÐºÑ†Ð¸Ñ Ð´Ð»Ñ Ð¾Ð±Ð½Ð°Ñ€ÑƒÐ¶ÐµÐ½Ð¸Ñ Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð° Ð² Ñ€Ð°Ð¼ÐºÐµ
  const startDocumentDetection = useCallback(() => {
    console.log('ðŸ” Ð—Ð°Ð¿ÑƒÑÐº Ð¾Ð±Ð½Ð°Ñ€ÑƒÐ¶ÐµÐ½Ð¸Ñ Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð°');
    
    if (!model) {
      console.log('âŒ ÐœÐ¾Ð´ÐµÐ»ÑŒ Ð½Ðµ Ð·Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½Ð°');
      return;
    }
    
    if (!cameraRef.current || !cameraRef.current.video) {
      console.log('âŒ ÐšÐ°Ð¼ÐµÑ€Ð° Ð½Ðµ Ð³Ð¾Ñ‚Ð¾Ð²Ð°');
      return;
    }

    if (detectionIntervalRef.current) {
      clearInterval(detectionIntervalRef.current);
    }

    detectionIntervalRef.current = setInterval(async () => {
      try {
        const video = cameraRef.current.video;
        if (!video || video.readyState !== 4) {
          console.log('â³ Ð’Ð¸Ð´ÐµÐ¾ Ð½Ðµ Ð³Ð¾Ñ‚Ð¾Ð²Ð¾');
          return;
        }

        console.log('ðŸŽ¯ ÐÐ½Ð°Ð»Ð¸Ð· ÐºÐ°Ð´Ñ€Ð°...');
        const predictions = await model.detect(video);
        console.log('ðŸ“Š ÐÐ°Ð¹Ð´ÐµÐ½Ð¾ Ð¾Ð±ÑŠÐµÐºÑ‚Ð¾Ð²:', predictions.length);
        
        if (predictions.length > 0) {
          console.log('ðŸ“‹ ÐžÐ±ÑŠÐµÐºÑ‚Ñ‹:', predictions.map(p => `${p.class} (${Math.round(p.score * 100)}%)`));
        }
        
        // Ð ÐÐ¡Ð¨Ð˜Ð Ð•ÐÐÐ«Ð™ ÑÐ¿Ð¸ÑÐ¾Ðº Ð¾Ð±ÑŠÐµÐºÑ‚Ð¾Ð² Ð´Ð»Ñ Ð¾Ð±Ð½Ð°Ñ€ÑƒÐ¶ÐµÐ½Ð¸Ñ
        const documentLikeObjects = predictions.filter(pred => 
          ['book', 'laptop', 'cell phone'].includes(pred.class) && 
          pred.score > 0.6
        );

        console.log('ðŸ“„ ÐŸÐ¾Ð´Ñ…Ð¾Ð´ÑÑ‰Ð¸Ðµ Ð¾Ð±ÑŠÐµÐºÑ‚Ñ‹ (60%+):', documentLikeObjects.length);

        if (documentLikeObjects.length > 0) {
          const bestMatch = documentLikeObjects[0];
          console.log('ðŸŽ¯ Ð›ÑƒÑ‡ÑˆÐ¸Ð¹ ÐºÐ°Ð½Ð´Ð¸Ð´Ð°Ñ‚:', bestMatch.class, `(${Math.round(bestMatch.score * 100)}%)`);
          
          const inFrame = isObjectInFrame(bestMatch, video);
          console.log('ðŸŽ¯ Ð’ Ñ€Ð°Ð¼ÐºÐµ:', inFrame);
          
          if (inFrame) {
            console.log('âœ… ÐžÐ±ÑŠÐµÐºÑ‚ Ð¾Ð±Ð½Ð°Ñ€ÑƒÐ¶ÐµÐ½ Ð² Ñ€Ð°Ð¼ÐºÐµ!');
            const image = captureFrameArea(); // Ð˜Ð¡ÐŸÐžÐ›Ð¬Ð—Ð£Ð•Ðœ ÐÐžÐ’Ð£Ð® Ð¤Ð£ÐÐšÐ¦Ð˜Ð®
            if (image && onDocumentDetected) {
              console.log('ðŸ–¼ï¸ ÐŸÐµÑ€ÐµÐ´Ð°Ñ‡Ð° Ð¾Ð±Ñ€ÐµÐ·Ð°Ð½Ð½Ð¾Ð³Ð¾ Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ Ð² callback');
              onDocumentDetected(image);
              stopDocumentDetection();
            }
          } else {
            console.log('ðŸ“ ÐžÐ±ÑŠÐµÐºÑ‚ Ð½Ðµ Ð² Ñ€Ð°Ð¼ÐºÐµ, Ð½Ð¾ ÑƒÐ²ÐµÑ€ÐµÐ½Ð½Ð¾ÑÑ‚ÑŒ:', Math.round(bestMatch.score * 100) + '%');
          }
        } else {
          console.log('ðŸ” ÐÐµÑ‚ Ð¿Ð¾Ð´Ñ…Ð¾Ð´ÑÑ‰Ð¸Ñ… Ð¾Ð±ÑŠÐµÐºÑ‚Ð¾Ð²');
        }
      } catch (error) {
        console.error('âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¾Ð±Ð½Ð°Ñ€ÑƒÐ¶ÐµÐ½Ð¸Ñ:', error);
      }
    }, 1500); 
  }, [model, captureFrameArea, onDocumentDetected]);

  const stopDocumentDetection = useCallback(() => {
    console.log('ðŸ›‘ ÐžÑÑ‚Ð°Ð½Ð¾Ð²ÐºÐ° Ð¾Ð±Ð½Ð°Ñ€ÑƒÐ¶ÐµÐ½Ð¸Ñ');
    if (detectionIntervalRef.current) {
      clearInterval(detectionIntervalRef.current);
      detectionIntervalRef.current = null;
    }
  }, []);

  const isObjectInFrame = (prediction, video) => {
    const [x, y, width, height] = prediction.bbox;
    const targetZone = {
      x: (video.videoWidth - 350) / 2,
      y: (video.videoHeight - 250) / 2,
      width: 350,
      height: 250
    };

    // Ð¡ÐœÐ¯Ð“Ð§Ð•ÐÐÐ«Ð• ÐšÐ Ð˜Ð¢Ð•Ð Ð˜Ð˜ ÐŸÐžÐ—Ð˜Ð¦Ð˜Ð˜
    const isInZone = 
      x >= targetZone.x - 60 &&
      y >= targetZone.y - 60 &&
      x + width <= targetZone.x + targetZone.width + 60 &&
      y + height <= targetZone.y + targetZone.height + 60;

    const aspectRatio = width / height;
    const zoneArea = targetZone.width * targetZone.height;
    const objectArea = width * height;
    const coverage = objectArea / zoneArea;

    // Ð¡ÐœÐ¯Ð“Ð§Ð•ÐÐÐ«Ð• Ð ÐÐ¡Ð§Ð•Ð¢Ð« Ð¡ÐžÐ’ÐŸÐÐ”Ð•ÐÐ˜Ð¯
    const zoneMatch = calculateZoneMatch(x, y, width, height, targetZone);
    const aspectMatch = calculateAspectMatch(aspectRatio);
    const sizeMatch = calculateSizeMatch(coverage);
    
    const totalMatch = (zoneMatch + aspectMatch + sizeMatch) / 3;
    const isHighMatch = totalMatch >= 0.5;

    console.log(`ðŸŽ¯ Ð”ÐµÑ‚Ð°Ð»ÑŒÐ½Ñ‹Ð¹ Ð°Ð½Ð°Ð»Ð¸Ð·:`);
    console.log(`   ðŸ“ ÐŸÐ¾Ð·Ð¸Ñ†Ð¸Ñ: x=${Math.round(x)}, y=${Math.round(y)}`);
    console.log(`   ðŸ“ Ð Ð°Ð·Ð¼ÐµÑ€: ${Math.round(width)}x${Math.round(height)}`);
    console.log(`   ðŸŽ¯ Ð’ Ð·Ð¾Ð½Ðµ: ${isInZone} (${Math.round(zoneMatch * 100)}%)`);
    console.log(`   ðŸ“ ÐŸÑ€Ð¾Ð¿Ð¾Ñ€Ñ†Ð¸Ð¸: ${aspectRatio.toFixed(2)} (${Math.round(aspectMatch * 100)}%)`);
    console.log(`   ðŸ“Š ÐŸÐ¾ÐºÑ€Ñ‹Ñ‚Ð¸Ðµ: ${(coverage * 100).toFixed(1)}% (${Math.round(sizeMatch * 100)}%)`);
    console.log(`   ðŸŽ¯ ÐžÐ‘Ð©Ð•Ð• Ð¡ÐžÐ’ÐŸÐÐ”Ð•ÐÐ˜Ð•: ${Math.round(totalMatch * 100)}%`);
    console.log(`   ðŸŽ¯ Ð˜Ñ‚Ð¾Ð³: ${isHighMatch ? 'âœ… ÐžÐ‘ÐÐÐ Ð£Ð–Ð•Ð (>50%)' : 'âŒ ÐÐ•Ð”ÐžÐ¡Ð¢ÐÐ¢ÐžÐ§ÐÐž'}`);
    
    return isHighMatch;
  };

  const calculateZoneMatch = (x, y, width, height, targetZone) => {
    const centerX = x + width / 2;
    const centerY = y + height / 2;
    const targetCenterX = targetZone.x + targetZone.width / 2;
    const targetCenterY = targetZone.y + targetZone.height / 2;
    
    const distanceX = Math.abs(centerX - targetCenterX);
    const distanceY = Math.abs(centerY - targetCenterY);
    
    const maxDistanceX = targetZone.width / 2 + 60;
    const maxDistanceY = targetZone.height / 2 + 60;
    
    const matchX = Math.max(0, 1 - distanceX / maxDistanceX);
    const matchY = Math.max(0, 1 - distanceY / maxDistanceY);
    
    return (matchX + matchY) / 2;
  };

  const calculateAspectMatch = (aspectRatio) => {
    const idealAspect = 1.4; 
    const deviation = Math.abs(aspectRatio - idealAspect);
    const maxDeviation = 1.0;
    
    return Math.max(0, 1 - deviation / maxDeviation);
  };

  const calculateSizeMatch = (coverage) => {
    const idealCoverage = 0.7;
    const deviation = Math.abs(coverage - idealCoverage);
    const maxDeviation = 0.8;
    
    return Math.max(0, 1 - deviation / maxDeviation);
  };

  return {
    isCameraActive,
    cameraRef,
    startCamera,
    stopCamera,
    capturePhoto: captureFrameArea,
    startDocumentDetection,
    stopDocumentDetection,
    modelLoaded: !!model
  };
};